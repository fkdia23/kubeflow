 
 
RAPPORT MINI PROJET MLOPS - DEVOPS - KUBEFLOW
 
Paris 14 FÃ©vrier 2025 
  
 	 
Majeur : Master of Science , Data Engineering 
 
Membres du groupe : 
-	Edson KANOU TAYOUTSTOP 
-	Daina Stela KAMTA TCHOUYON 
-	Franklin KANA NGUEDIA  
 	 	 	 	 	 	 

Table des matiÃ¨res
INTRODUCTION	2
Partie 1 : PrÃ©traitement des DonnÃ©es	2
Ã‰tape 1 : Exploration initiale	2
Ã‰tape 2 : Gestion des valeurs manquantes	4
Variables avec un taux Ã©levÃ© de valeurs manquantes (â‰¥ 80%)	4
Variables avec un taux modÃ©rÃ© de valeurs manquantes (10% 60%)	4
Variables avec peu de valeurs manquantes (â‰¤ 5.5%)	5
Partie applicative 1:	7
Partie 2 : SÃ©lection des Variables Pertinentes	8
Ã‰tape 1 :  Calculer la corrÃ©lation entre les variables	8
Etape 2 : Comparez les deux approches (corrÃ©lation et PCA) et interprÃ©tez les rÃ©sultats	9
Etape 3 : Application du PCA	9
InterprÃ©tation et recommandations	9
Partie 3 : RÃ©Ã©chantillonnage des DonnÃ©es DÃ©sÃ©quilibrÃ©es	10
2.	Afficher la distribution de la valeur de sortie aprÃ¨s	11
Partie 4 : ModÃ©lisation et Ã‰valuation	12
Ã‰tape 1 : Conception des modÃ¨les intelligents	12
Comparez les performances des modÃ¨les et discutez des rÃ©sultats.	13
Analyse globale des performances	13
Partie applicative :	14




















INTRODUCTION 
L'objectif de ce mini projet est de dÃ©velopper une chaÃ®ne complÃ¨te pour rÃ©soudre un problÃ¨me de classification supervisÃ©e visant Ã  prÃ©dire les prix des maisons en retard 
Nous serons amenÃ© Ã  nettoyer et transformer un jeu de donnÃ©es, entraÃ®ner plusieurs modÃ¨les intelligents, et dÃ©ployer le modÃ¨le final dans un environnement de production Ã  l'aide de technologies modernes telle que Docker, Jenkins, Kubernetes et Kubeflow.

Partie 1 : PrÃ©traitement des DonnÃ©es
Ã‰tape 1 : Exploration initiale
1. Affichez les cinq premiÃ¨res lignes des ensembles dâ€™entraÃ®nement (TR) et de test (TS).
 
 
 
1.	Obtenez les dimensions des deux ensembles.
 
2.	Identifiez les types de variables prÃ©sentes dans les datasets.
 

Ã‰tape 2 : Gestion des valeurs manquantes

1. Identifiez les valeurs manquantes dans chaque colonne et calculez leur pourcentage.
InterprÃ©ter les rÃ©sultats.
 
Variables avec un taux Ã©levÃ© de valeurs manquantes (â‰¥ 80%)
  PoolQC (99.52%) : QualitÃ© de la piscine. La quasi-totalitÃ© des maisons n'a probablement pas de piscine. Il peut Ãªtre pertinent de remplacer les valeurs manquantes par "None" ou un indicateur de l'absence de piscine.
  MiscFeature (96.30%) : PrÃ©sence d'une caractÃ©ristique spÃ©ciale (par exemple, une cabane de jardin). Beaucoup de maisons ne semblent pas en avoir, donc remplacer les valeurs manquantes par "None" est une option.
  Alley (93.77%) : AccÃ¨s par une allÃ©e. La majoritÃ© des maisons nâ€™ont probablement pas d'accÃ¨s Ã  une allÃ©e, donc "None" peut Ãªtre une bonne solution.
  Fence (80.75%) : PrÃ©sence d'une clÃ´ture. Beaucoup de maisons nâ€™ont pas de clÃ´ture, donc "None" est une valeur de remplacement logique.
ğŸ‘‰ InterprÃ©tation 1 : Ces variables sont souvent absentes car la caractÃ©ristique nâ€™existe pas dans la majoritÃ© des maisons. Remplacer les valeurs par une catÃ©gorie "None" ou "Pas de X" est plus pertinent quâ€™une imputation par la moyenne ou la mÃ©diane.
Variables avec un taux modÃ©rÃ© de valeurs manquantes (10% 60%)
  MasVnrType (59.73%) et MasVnrArea (0.54%) : Type et surface de la maÃ§onnerie en pierre (masonry veneer). Beaucoup de maisons nâ€™ont probablement pas de revÃªtement en pierre, donc "None" pour le type et 0 pour l'aire sont des imputations possibles.
  FireplaceQu (47.26%) : QualitÃ© de la cheminÃ©e. La moitiÃ© des maisons nâ€™a pas de cheminÃ©e, donc "None" est adaptÃ©.
  LotFrontage (17.74%) : Longueur de la faÃ§ade donnant sur la rue. Les valeurs manquantes pourraient Ãªtre imputÃ©es par la mÃ©diane en fonction du quartier
(Neighborhood), car des quartiers similaires ont souvent des largeurs de lots similaires.
ğŸ‘‰ InterprÃ©tation 2 : Certaines caractÃ©ristiques (ex. cheminÃ©e, maÃ§onnerie) sont absentes par nature, donc un remplacement par "None" ou 0 est pertinent. Pour LotFrontage, il est plus judicieux dâ€™utiliser des mÃ©thodes basÃ©es sur des caractÃ©ristiques similaires (ex. mÃ©diane par quartier).
Variables avec peu de valeurs manquantes (â‰¤ 5.5%)
  GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond (5.55%) : Informations sur le garage. Ici, il est probable que les maisons sans garage soient responsables des valeurs manquantes. Il serait pertinent de remplacer :
GarageType par "None"
GarageYrBlt par 0 (ou mÃ©diane si pertinent)
GarageFinish , GarageQual , GarageCond par "None"
BsmtExposure, BsmtFinType2, BsmtQual, BsmtCond, BsmtFinType1 (2.5% - 2.6%) : Informations sur le sous-sol. Comme pour le garage, les valeurs manquantes peuvent Ãªtre remplacÃ©es par "None" si elles signifient une absence de sous-sol.
  Electrical (0.07%) : Type de systÃ¨me Ã©lectrique. Seule une trÃ¨s petite partie des donnÃ©es est affectÃ©e. Une imputation par la valeur la plus frÃ©quente (mode) est appropriÃ©e ici.
ğŸ‘‰ InterprÃ©tation 3 : Les garages et sous-sols absents entraÃ®nent des valeurs nulles. Remplacer par "None" est logique. Pour Electrical, une imputation par le mode est suffisante.
âœ… CatÃ©gories Ã  remplacer par "None" : PoolQC, MiscFeature, Alley, Fence, FireplaceQu,
GarageType, GarageFinish, GarageQual, GarageCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2.
âœ… CatÃ©gories Ã  remplacer par 0 : MasVnrArea, GarageYrBlt (si pertinent).
âœ… CatÃ©gories Ã  imputer par la mÃ©diane (en groupe par quartier) : LotFrontage.
âœ… CatÃ©gories Ã  imputer par la valeur la plus frÃ©quente (mode) : Electrical.
2.Affichez des tableaux de statistiques descriptives pour TR et TS (moyennes, mÃ©dianes, Ã©carts-types).
 
3.	 Proposez des solutions pour traiter les valeurs manquantes.
Le dataset prÃ©sente une large gamme de caractÃ©ristiques pour les maisons, avec des variations significatives dans la taille des terrains, l'annÃ©e de construction et la qualitÃ© globale des logements. La superficie des terrains varie fortement, allant de 1 300 Ã  plus de 215 000 pieds carrÃ©s, avec une mÃ©diane autour de 9 478 pieds carrÃ©s. La qualitÃ© des maisons, mesurÃ©e par OverallQual, oscille entre 1 et 10, avec une moyenne de 6, indiquant que la majoritÃ© des logements ont une qualitÃ© moyenne Ã  bonne. De plus, la colonne LotFrontage a des valeurs manquantes, ce qui pourrait nÃ©cessiter une imputation, idÃ©alement en fonction du quartier.
En ce qui concerne les Ã©lÃ©ments extÃ©rieurs et annexes, la majoritÃ© des maisons nâ€™ont ni piscine (PoolArea, mÃ©diane = 0), ni porches fermÃ©s (EnclosedPorch), ni structures spÃ©ciales (MiscVal). La variabilitÃ© des prix de vente est importante, avec un prix mÃ©dian de 163 000 dollars, mais pouvant aller jusquâ€™Ã  755 000 dollars. La distribution des prix montre une asymÃ©trie vers les valeurs Ã©levÃ©es, suggÃ©rant la prÃ©sence de quelques propriÃ©tÃ©s de luxe. Enfin, les maisons rÃ©centes (annÃ©es 2000+) semblent mieux reprÃ©sentÃ©es, ce qui pourrait influencer les tendances du prix de vente et nÃ©cessiter une
	





Partie applicative 1:
â— Utilisez Docker pour conteneuriser votre script Python de nettoyage des donnÃ©es afin de garantir une exÃ©cution reproductible avec les dÃ©pendances nÃ©cessaires (Pandas,NumPy, etc.).
 









Partie 2 : SÃ©lection des Variables Pertinentes

Ã‰tape 1 :  Calculer la corrÃ©lation entre les variables 

Appliquer le test de khi deux pour les variables catÃ©gorielles. Si la valeur de corrÃ©lation dÃ©passe 90% (les deux variables sont fortement corrÃ©lÃ©es) Ã©liminer lâ€™une de valeurs de DS. Laquelle quâ€™on doit Ã©liminer et pourquoi ? Câ€™est quoi la nouvelle dimensionnalitÃ© de notre DS ?
 
 
Etape 2 : Comparez les deux approches (corrÃ©lation et PCA) et interprÃ©tez les rÃ©sultats

Analyse des corrÃ©lations

Aucune variable nâ€™a dÃ©passÃ© le seuil de 0.9 en corrÃ©lation, ce qui signifie que le dataset ne contient pas de redondances significatives. Par consÃ©quent, la suppression des variables corrÃ©lÃ©es nâ€™a pas rÃ©duit la dimensionnalitÃ©, qui reste Ã   77 variables.

Etape 3 : Application du PCA 

Le PCA a permis de ramener la dimensionnalitÃ© de 77 Ã  27 composantes principales tout en conservant 95% de la variance totale. Cela montre une forte compression de lâ€™information, rÃ©duisant la complexitÃ© du dataset de plus de 65% sans perte majeure dâ€™information.
InterprÃ©tation et recommandations
-	Si lâ€™objectif est la performance dâ€™un modÃ¨le prÃ©dictif, il est prÃ©fÃ©rable dâ€™utiliser les 27 composantes principales issues du PCA, car elles rÃ©sument efficacement les donnÃ©es et accÃ©lÃ¨rent les calculs
-	Si lâ€™interprÃ©tabilitÃ© est essentielle, il est prÃ©fÃ©rable de conserver toutes les variables d'origine, puisque la corrÃ©lation nâ€™a rÃ©vÃ©lÃ© aucune redondance majeure.
Le PCA se rÃ©vÃ¨le donc Ãªtre la mÃ©thode la plus efficace pour ce dataset spÃ©cifique, offrant une rÃ©duction significative de la dimensionnalitÃ© tout en conservant une forte capacitÃ© explicative









Partie 3 : RÃ©Ã©chantillonnage des DonnÃ©es DÃ©sÃ©quilibrÃ©es
1.	Appliquer une mÃ©thode de surÃ©chantillonnage (Oversampling) pour rÃ©soudre le problÃ¨me de dÃ©sÃ©quilibre.
 
 
InterprÃ©tation :
La distribution des prix suit une tendance normale pour lâ€™immobilier, avec une grande majoritÃ© de prix modÃ©rÃ©s et quelques valeurs extrÃªmes.
Lâ€™asymÃ©trie pourrait impacter certains modÃ¨les, en particulier ceux sensibles aux valeurs extrÃªmes (comme les rÃ©gressions linÃ©aires classiques). Des transformations comme log(SalePrice) pourraient amÃ©liorer les performances. Le dataset initial Ã©tait dÃ©jÃ  remarquablement Ã©quilibrÃ©
le rÃ©echantillonage n'Ã©tait pas nÃ©cessaire vu le faible dÃ©sÃ©quilibre initial
 
2.	Afficher la distribution de la valeur de sortie aprÃ¨s le rÃ©Ã©chantillonnage.
 

Le rÃ©Ã©chantillonnage n'Ã©tait pas nÃ©cessaire vu le faible dÃ©sÃ©quilibre initial












Partie 4 : ModÃ©lisation et Ã‰valuation
Ã‰tape 1 : Conception des modÃ¨les intelligents
 EntraÃ®nez un classificateur basÃ© sur un  modÃ¨le :
â—‹ Artificial Neural Network (ANN)
 

 
 
Comparez les performances des modÃ¨les et discutez des rÃ©sultats.
Analyse globale des performances
MÃ©trique	Avant Ã©chantillonnage	AprÃ¨s Ã©chantillonnage	Variation
Accuracy	91%	88%	ğŸ”» -3%
Macro avg F1-score	0.91	0.88	ğŸ”» -0.03
Weighted avg F1-score	0.91	0.88	ğŸ”» -0.03
			
Classe	Faux positifs avant	Faux positifs aprÃ¨s	Faux nÃ©gatifs avant	Faux nÃ©gatifs aprÃ¨s
0	5	3	5	3
1	16	18	16	18
2	2	5	2	5
3	3	7	3	7
ğŸ“Œ Classe 0 : Moins de faux positifs et faux nÃ©gatifs â†’ amÃ©lioration.
ğŸ“Œ Classe 1 : Augmentation des erreurs, notamment en classification avec la classe 0.
ğŸ“Œ Classe 2 : Plus dâ€™erreurs aprÃ¨s Ã©chantillonnage.
ğŸ“Œ Classe 3 : Plus dâ€™erreurs Ã©galement.
Observation gÃ©nÃ©rale : Lâ€™accuracy et le F1-score global ont lÃ©gÃ¨rement baissÃ© aprÃ¨s l'Ã©chantillonnage. Cela peut Ãªtre dÃ» Ã  un meilleur Ã©quilibrage des classes, qui peut parfois introduire de lÃ©gÃ¨res pertes sur certaines performances globales.
Lâ€™Ã©chantillonnage a amÃ©liorÃ© lâ€™Ã©quilibre des classes, mais au prix dâ€™une lÃ©gÃ¨re baisse de performance globale.

Partie applicative :
â—	Automatisez lâ€™entraÃ®nement avec Jenkins pour permettre une exÃ©cution continue (CI/CD)lorsque le code ou les donnÃ©es changent.
 
 
â—	CrÃ©ez un pipeline Jenkins qui :
1.	TÃ©lÃ©charge les donnees sur git .
2.	Nettoie et EntraÃ®ne les donnÃ©es avec le script DockerisÃ©.
3.	EntraÃ®ne le modÃ¨le et stocke les artefacts gÃ©nÃ©rÃ©s (modÃ¨le entraÃ®nÃ©, logs, mÃ©triques).
 
 
NB : Le scripts clean_data.ipynb fait office de precessing , et d'entrainement dans notre cas
Partie 5 : DÃ©ploiement en Production
Ã‰tape 1 : Conteneurisation avec Docker Compose structure globale de l'application
ğŸ“‚ kubeflow/
â”‚â”€â”€ ğŸ“‚ api/ # Contient l'API (Flask)
â”‚ â”‚â”€â”€ app.py # Code du serveur API
â”‚ â”‚â”€â”€ requirements.txt # DÃ©pendances de l'API
â”‚ â”‚â”€â”€ Dockerfile # Dockerfile pour l'API
â”‚
â”‚â”€â”€ ğŸ“‚ work/ # Contient le modÃ¨le et son serveur
â”‚ â”‚â”€â”€ clean_data.py # Script d'entraÃ®nement et pre-traitement
â”‚ â”‚â”€â”€ predict.py # Script d'infÃ©rence
â”‚ â”‚â”€â”€ model.pkl # ModÃ¨le entraÃ®nÃ©
â”‚ â”‚â”€â”€ requirements.txt # DÃ©pendances du modÃ¨le
â”‚ â”‚â”€â”€ Dockerfile # Dockerfile pour le modÃ¨le
â”‚
â”‚â”€â”€ ğŸ“‚ dataset/ # Contient les donnÃ©es brutes et nettoyÃ©es
â”‚ â”‚â”€â”€ train.csv
â”‚ â”‚â”€â”€ test.csv
|
â”‚â”€â”€ Jenkinsfile # Contient le script du pipeline Jenkins
â”‚
â”‚â”€â”€ ğŸ“‚ db/ # Contient la configuration de la base de donnÃ©es
â”‚ â”‚â”€â”€ init.sql # Script SQL d'initialisation (facultatif)
â”‚
â”‚â”€â”€ docker-compose.yml # Orchestration avec Docker Compose
â”‚â”€â”€ .gitignore # Fichier Git ignore
â”‚â”€â”€ README.md # Documentation du projet

1. Utilisez Docker Compose pour orchestrer lâ€™environnement, incluant :
â—‹ Un conteneur pour le modÃ¨le dÃ©ployÃ©.
â—‹ Un conteneur pour un serveur API (par exemple, Flask ou FastAPI).
â—‹ Un conteneur pour une base de donnÃ©es de stockage des prÃ©dictions.
 
 
 
