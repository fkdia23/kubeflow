 
 
RAPPORT MINI PROJET MLOPS - DEVOPS - KUBEFLOW
 
Paris 14 F√©vrier 2025 
  
 	 
Majeur : Master of Science , Data Engineering 
 
Membres du groupe : 
-	Edson KANOU TAYOUTSTOP 
-	Daina Stela KAMTA TCHOUYON 
-	Franklin KANA NGUEDIA  
 	 	 	 	 	 	 

Table des mati√®res
INTRODUCTION	2
Partie 1 : Pr√©traitement des Donn√©es	2
√âtape 1 : Exploration initiale	2
√âtape 2 : Gestion des valeurs manquantes	4
Variables avec un taux √©lev√© de valeurs manquantes (‚â• 80%)	4
Variables avec un taux mod√©r√© de valeurs manquantes (10% 60%)	4
Variables avec peu de valeurs manquantes (‚â§ 5.5%)	5
Partie applicative 1:	7
Partie 2 : S√©lection des Variables Pertinentes	8
√âtape 1 :  Calculer la corr√©lation entre les variables	8
Etape 2 : Comparez les deux approches (corr√©lation et PCA) et interpr√©tez les r√©sultats	9
Etape 3 : Application du PCA	9
Interpr√©tation et recommandations	9
Partie 3 : R√©√©chantillonnage des Donn√©es D√©s√©quilibr√©es	10
2.	Afficher la distribution de la valeur de sortie apr√®s	11
Partie 4 : Mod√©lisation et √âvaluation	12
√âtape 1 : Conception des mod√®les intelligents	12
Comparez les performances des mod√®les et discutez des r√©sultats.	13
Analyse globale des performances	13
Partie applicative :	14




















INTRODUCTION 
L'objectif de ce mini projet est de d√©velopper une cha√Æne compl√®te pour r√©soudre un probl√®me de classification supervis√©e visant √† pr√©dire les prix des maisons en retard 
Nous serons amen√© √† nettoyer et transformer un jeu de donn√©es, entra√Æner plusieurs mod√®les intelligents, et d√©ployer le mod√®le final dans un environnement de production √† l'aide de technologies modernes telle que Docker, Jenkins, Kubernetes et Kubeflow.

Partie 1 : Pr√©traitement des Donn√©es
√âtape 1 : Exploration initiale
1. Affichez les cinq premi√®res lignes des ensembles d‚Äôentra√Ænement (TR) et de test (TS).
 
 
 
1.	Obtenez les dimensions des deux ensembles.
 
2.	Identifiez les types de variables pr√©sentes dans les datasets.
 

√âtape 2 : Gestion des valeurs manquantes

1. Identifiez les valeurs manquantes dans chaque colonne et calculez leur pourcentage.
Interpr√©ter les r√©sultats.
 
Variables avec un taux √©lev√© de valeurs manquantes (‚â• 80%)
  PoolQC (99.52%) : Qualit√© de la piscine. La quasi-totalit√© des maisons n'a probablement pas de piscine. Il peut √™tre pertinent de remplacer les valeurs manquantes par "None" ou un indicateur de l'absence de piscine.
  MiscFeature (96.30%) : Pr√©sence d'une caract√©ristique sp√©ciale (par exemple, une cabane de jardin). Beaucoup de maisons ne semblent pas en avoir, donc remplacer les valeurs manquantes par "None" est une option.
  Alley (93.77%) : Acc√®s par une all√©e. La majorit√© des maisons n‚Äôont probablement pas d'acc√®s √† une all√©e, donc "None" peut √™tre une bonne solution.
  Fence (80.75%) : Pr√©sence d'une cl√¥ture. Beaucoup de maisons n‚Äôont pas de cl√¥ture, donc "None" est une valeur de remplacement logique.
üëâ Interpr√©tation 1 : Ces variables sont souvent absentes car la caract√©ristique n‚Äôexiste pas dans la majorit√© des maisons. Remplacer les valeurs par une cat√©gorie "None" ou "Pas de X" est plus pertinent qu‚Äôune imputation par la moyenne ou la m√©diane.
Variables avec un taux mod√©r√© de valeurs manquantes (10% 60%)
  MasVnrType (59.73%) et MasVnrArea (0.54%) : Type et surface de la ma√ßonnerie en pierre (masonry veneer). Beaucoup de maisons n‚Äôont probablement pas de rev√™tement en pierre, donc "None" pour le type et 0 pour l'aire sont des imputations possibles.
  FireplaceQu (47.26%) : Qualit√© de la chemin√©e. La moiti√© des maisons n‚Äôa pas de chemin√©e, donc "None" est adapt√©.
  LotFrontage (17.74%) : Longueur de la fa√ßade donnant sur la rue. Les valeurs manquantes pourraient √™tre imput√©es par la m√©diane en fonction du quartier
(Neighborhood), car des quartiers similaires ont souvent des largeurs de lots similaires.
üëâ Interpr√©tation 2 : Certaines caract√©ristiques (ex. chemin√©e, ma√ßonnerie) sont absentes par nature, donc un remplacement par "None" ou 0 est pertinent. Pour LotFrontage, il est plus judicieux d‚Äôutiliser des m√©thodes bas√©es sur des caract√©ristiques similaires (ex. m√©diane par quartier).
Variables avec peu de valeurs manquantes (‚â§ 5.5%)
  GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond (5.55%) : Informations sur le garage. Ici, il est probable que les maisons sans garage soient responsables des valeurs manquantes. Il serait pertinent de remplacer :
GarageType par "None"
GarageYrBlt par 0 (ou m√©diane si pertinent)
GarageFinish , GarageQual , GarageCond par "None"
BsmtExposure, BsmtFinType2, BsmtQual, BsmtCond, BsmtFinType1 (2.5% - 2.6%) : Informations sur le sous-sol. Comme pour le garage, les valeurs manquantes peuvent √™tre remplac√©es par "None" si elles signifient une absence de sous-sol.
  Electrical (0.07%) : Type de syst√®me √©lectrique. Seule une tr√®s petite partie des donn√©es est affect√©e. Une imputation par la valeur la plus fr√©quente (mode) est appropri√©e ici.
üëâ Interpr√©tation 3 : Les garages et sous-sols absents entra√Ænent des valeurs nulles. Remplacer par "None" est logique. Pour Electrical, une imputation par le mode est suffisante.
‚úÖ Cat√©gories √† remplacer par "None" : PoolQC, MiscFeature, Alley, Fence, FireplaceQu,
GarageType, GarageFinish, GarageQual, GarageCond, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2.
‚úÖ Cat√©gories √† remplacer par 0 : MasVnrArea, GarageYrBlt (si pertinent).
‚úÖ Cat√©gories √† imputer par la m√©diane (en groupe par quartier) : LotFrontage.
‚úÖ Cat√©gories √† imputer par la valeur la plus fr√©quente (mode) : Electrical.
2.Affichez des tableaux de statistiques descriptives pour TR et TS (moyennes, m√©dianes, √©carts-types).
 
3.	 Proposez des solutions pour traiter les valeurs manquantes.
Le dataset pr√©sente une large gamme de caract√©ristiques pour les maisons, avec des variations significatives dans la taille des terrains, l'ann√©e de construction et la qualit√© globale des logements. La superficie des terrains varie fortement, allant de 1 300 √† plus de 215 000 pieds carr√©s, avec une m√©diane autour de 9 478 pieds carr√©s. La qualit√© des maisons, mesur√©e par OverallQual, oscille entre 1 et 10, avec une moyenne de 6, indiquant que la majorit√© des logements ont une qualit√© moyenne √† bonne. De plus, la colonne LotFrontage a des valeurs manquantes, ce qui pourrait n√©cessiter une imputation, id√©alement en fonction du quartier.
En ce qui concerne les √©l√©ments ext√©rieurs et annexes, la majorit√© des maisons n‚Äôont ni piscine (PoolArea, m√©diane = 0), ni porches ferm√©s (EnclosedPorch), ni structures sp√©ciales (MiscVal). La variabilit√© des prix de vente est importante, avec un prix m√©dian de 163 000 dollars, mais pouvant aller jusqu‚Äô√† 755 000 dollars. La distribution des prix montre une asym√©trie vers les valeurs √©lev√©es, sugg√©rant la pr√©sence de quelques propri√©t√©s de luxe. Enfin, les maisons r√©centes (ann√©es 2000+) semblent mieux repr√©sent√©es, ce qui pourrait influencer les tendances du prix de vente et n√©cessiter une
	





Partie applicative 1:
‚óè Utilisez Docker pour conteneuriser votre script Python de nettoyage des donn√©es afin de garantir une ex√©cution reproductible avec les d√©pendances n√©cessaires (Pandas,NumPy, etc.).
 









Partie 2 : S√©lection des Variables Pertinentes

√âtape 1 :  Calculer la corr√©lation entre les variables 

Appliquer le test de khi deux pour les variables cat√©gorielles. Si la valeur de corr√©lation d√©passe 90% (les deux variables sont fortement corr√©l√©es) √©liminer l‚Äôune de valeurs de DS. Laquelle qu‚Äôon doit √©liminer et pourquoi ? C‚Äôest quoi la nouvelle dimensionnalit√© de notre DS ?
 
 
Etape 2 : Comparez les deux approches (corr√©lation et PCA) et interpr√©tez les r√©sultats

Analyse des corr√©lations

Aucune variable n‚Äôa d√©pass√© le seuil de 0.9 en corr√©lation, ce qui signifie que le dataset ne contient pas de redondances significatives. Par cons√©quent, la suppression des variables corr√©l√©es n‚Äôa pas r√©duit la dimensionnalit√©, qui reste √†  77 variables.

Etape 3 : Application du PCA 

Le PCA a permis de ramener la dimensionnalit√© de 77 √† 27 composantes principales tout en conservant 95% de la variance totale. Cela montre une forte compression de l‚Äôinformation, r√©duisant la complexit√© du dataset de plus de 65% sans perte majeure d‚Äôinformation.
Interpr√©tation et recommandations
-	Si l‚Äôobjectif est la performance d‚Äôun mod√®le pr√©dictif, il est pr√©f√©rable d‚Äôutiliser les 27 composantes principales issues du PCA, car elles r√©sument efficacement les donn√©es et acc√©l√®rent les calculs
-	Si l‚Äôinterpr√©tabilit√© est essentielle, il est pr√©f√©rable de conserver toutes les variables d'origine, puisque la corr√©lation n‚Äôa r√©v√©l√© aucune redondance majeure.
Le PCA se r√©v√®le donc √™tre la m√©thode la plus efficace pour ce dataset sp√©cifique, offrant une r√©duction significative de la dimensionnalit√© tout en conservant une forte capacit√© explicative









Partie 3 : R√©√©chantillonnage des Donn√©es D√©s√©quilibr√©es
1.	Appliquer une m√©thode de sur√©chantillonnage (Oversampling) pour r√©soudre le probl√®me de d√©s√©quilibre.
 
 
Interpr√©tation :
La distribution des prix suit une tendance normale pour l‚Äôimmobilier, avec une grande majorit√© de prix mod√©r√©s et quelques valeurs extr√™mes.
L‚Äôasym√©trie pourrait impacter certains mod√®les, en particulier ceux sensibles aux valeurs extr√™mes (comme les r√©gressions lin√©aires classiques). Des transformations comme log(SalePrice) pourraient am√©liorer les performances. Le dataset initial √©tait d√©j√† remarquablement √©quilibr√©
le r√©echantillonage n'√©tait pas n√©cessaire vu le faible d√©s√©quilibre initial
 
2.	Afficher la distribution de la valeur de sortie apr√®s le r√©√©chantillonnage.
 

Le r√©√©chantillonnage n'√©tait pas n√©cessaire vu le faible d√©s√©quilibre initial












Partie 4 : Mod√©lisation et √âvaluation
√âtape 1 : Conception des mod√®les intelligents
 Entra√Ænez un classificateur bas√© sur un  mod√®le :
‚óã Artificial Neural Network (ANN)
 

 
 
Comparez les performances des mod√®les et discutez des r√©sultats.
Analyse globale des performances
M√©trique	Avant √©chantillonnage	Apr√®s √©chantillonnage	Variation
Accuracy	91%	88%	üîª -3%
Macro avg F1-score	0.91	0.88	üîª -0.03
Weighted avg F1-score	0.91	0.88	üîª -0.03
			
Classe	Faux positifs avant	Faux positifs apr√®s	Faux n√©gatifs avant	Faux n√©gatifs apr√®s
0	5	3	5	3
1	16	18	16	18
2	2	5	2	5
3	3	7	3	7
üìå Classe 0 : Moins de faux positifs et faux n√©gatifs ‚Üí am√©lioration.
üìå Classe 1 : Augmentation des erreurs, notamment en classification avec la classe 0.
üìå Classe 2 : Plus d‚Äôerreurs apr√®s √©chantillonnage.
üìå Classe 3 : Plus d‚Äôerreurs √©galement.
Observation g√©n√©rale : L‚Äôaccuracy et le F1-score global ont l√©g√®rement baiss√© apr√®s l'√©chantillonnage. Cela peut √™tre d√ª √† un meilleur √©quilibrage des classes, qui peut parfois introduire de l√©g√®res pertes sur certaines performances globales.
L‚Äô√©chantillonnage a am√©lior√© l‚Äô√©quilibre des classes, mais au prix d‚Äôune l√©g√®re baisse de performance globale.

Partie applicative :
‚óè	Automatisez l‚Äôentra√Ænement avec Jenkins pour permettre une ex√©cution continue (CI/CD)lorsque le code ou les donn√©es changent.
 
 
‚óè	Cr√©ez un pipeline Jenkins qui :
1.	T√©l√©charge les donnees sur git .
2.	Nettoie et Entra√Æne les donn√©es avec le script Dockeris√©.
3.	Entra√Æne le mod√®le et stocke les artefacts g√©n√©r√©s (mod√®le entra√Æn√©, logs, m√©triques).
 
 
NB : Le scripts clean_data.ipynb fait office de precessing , et d'entrainement dans notre cas
Partie 5 : D√©ploiement en Production
√âtape 1 : Conteneurisation avec Docker Compose structure globale de l'application
üìÇ kubeflow/
‚îÇ‚îÄ‚îÄ üìÇ api/ # Contient l'API (Flask)
‚îÇ ‚îÇ‚îÄ‚îÄ app.py # Code du serveur API
‚îÇ ‚îÇ‚îÄ‚îÄ requirements.txt # D√©pendances de l'API
‚îÇ ‚îÇ‚îÄ‚îÄ Dockerfile # Dockerfile pour l'API
‚îÇ
‚îÇ‚îÄ‚îÄ üìÇ work/ # Contient le mod√®le et son serveur
‚îÇ ‚îÇ‚îÄ‚îÄ clean_data.py # Script d'entra√Ænement et pre-traitement
‚îÇ ‚îÇ‚îÄ‚îÄ predict.py # Script d'inf√©rence
‚îÇ ‚îÇ‚îÄ‚îÄ model.pkl # Mod√®le entra√Æn√©
‚îÇ ‚îÇ‚îÄ‚îÄ requirements.txt # D√©pendances du mod√®le
‚îÇ ‚îÇ‚îÄ‚îÄ Dockerfile # Dockerfile pour le mod√®le
‚îÇ
‚îÇ‚îÄ‚îÄ üìÇ dataset/ # Contient les donn√©es brutes et nettoy√©es
‚îÇ ‚îÇ‚îÄ‚îÄ train.csv
‚îÇ ‚îÇ‚îÄ‚îÄ test.csv
|
‚îÇ‚îÄ‚îÄ Jenkinsfile # Contient le script du pipeline Jenkins
‚îÇ
‚îÇ‚îÄ‚îÄ üìÇ db/ # Contient la configuration de la base de donn√©es
‚îÇ ‚îÇ‚îÄ‚îÄ init.sql # Script SQL d'initialisation (facultatif)
‚îÇ
‚îÇ‚îÄ‚îÄ docker-compose.yml # Orchestration avec Docker Compose
‚îÇ‚îÄ‚îÄ .gitignore # Fichier Git ignore
‚îÇ‚îÄ‚îÄ README.md # Documentation du projet

1. Utilisez Docker Compose pour orchestrer l‚Äôenvironnement, incluant :
‚óã Un conteneur pour le mod√®le d√©ploy√©.
‚óã Un conteneur pour un serveur API (par exemple, Flask ou FastAPI).
‚óã Un conteneur pour une base de donn√©es de stockage des pr√©dictions.
 
 
 
